<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Dildar Ali</title>
  
  <meta name="author" content="Dildar Ali">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Dildar Ali</name>
              </p>
              <p>I am a Ph.D. Research Scholar being advised by Dr. Suman Banerjee and Dr. Yamuna Prasad in the CSE Department at IIT Jammu since 2022. I primarily work in the area of Submodular Functions, Graph Theory, and Graph Algorithms.
              </p>
              <p>
                I have completed my M.Tech in Computer Science and Engineering from Aliah University (A State University), Kolkata, India under the supervision of Dr. Abhishek Das (Associate Professor, AU, Kolkata) in 2020. I have also worked as Project Associate at Indian Institute of Technology Bhilai, India under the supervision of Prof. Rajat Moona (Director, IIT Bhilai) and Dr. Dhiman Saha (Assistant Professor, IIT Bhilai) in a MeitY-funded research project. 
              </p>
              <p style="text-align:center">
                <a href="mailto:dildar.ali@iitjammu.ac.in@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.co.in/citations?user=zvkUg_4AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/being_dildarali">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/dildariitjammu/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Dildar.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/JonBarron_circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="malle_stop()" onmouseover="malle_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='malle_image'>
                  <img src='images/BB.jpg' width="160"></div>
              <script type="text/javascript">
                function malle_start() {
                  document.getElementById('malle_image').style.opacity = "1";
                }

                function malle_stop() {
                  document.getElementById('malle_image').style.opacity = "0";
                }
                malle_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2207.06631">
                <papertitle>Influential Billboard Slot Selection using Pruned Submodularity Graph</papertitle>
              </a>
              <br>
	      <a href="https://iitjammu.ac.in/computer_science_engineering/post/phd-students-cse">Dildar Ali</a>, 
	      <a href="https://iitjammu.ac.in/computer_science_engineering/faculty-list/~sumanbanerjee">Suman Banerjee</a>, 
	      <a href="https://iitjammu.ac.in/computer_science_engineering/faculty-list/~yamunaprasad">Yamuna Prasad</a>, 
              <em>ADMA</em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2207.06631">arXiv</a>
              <p></p>
              <p>
               Given a
trajectory database D and its corresponding billboard database B, the problem
of Influential Billboard Slot Selection asks to choose a subset of k billboard slots
such that the influence is maximized.
              </p>
            </td>
          </tr>
	
		
		
		
		
		
		
          <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfsuper_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nerf_supervision.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/nerf_supervision.jpg' width="160">
              </div>
              <script type="text/javascript">
                function nerfsuper_start() {
                  document.getElementById('nerfsuper_image').style.opacity = "1";
                }

                function nerfsuper_stop() {
                  document.getElementById('nerfsuper_image').style.opacity = "0";
                }
                nerfsuper_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="http://yenchenlin.me/nerf-supervision/">
                <papertitle>NeRF-Supervision: Learning Dense Object Descriptors from Neural Radiance Fields</papertitle>
              </a>
              <br>
              <a href="https://yenchenlin.me/">Lin Yen-Chen</a>, 
              <a href="http://www.peteflorence.com/">Pete Florence</a>, 
              <strong>Jonathan T. Barron</strong>,  <br>
              <a href="https://scholar.google.com/citations?user=_BPdgV0AAAAJ&hl=en">Tsung-Yi Lin</a>, 
              <a href="https://meche.mit.edu/people/faculty/ALBERTOR@MIT.EDU">Alberto Rodriguez</a>,
              <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>
              <br>
              <em>ICRA</em>, 2022  
              <br>
							<a href="http://yenchenlin.me/nerf-supervision/">project page</a> / 
							<a href="https://arxiv.org/abs/2203.01913">arXiv</a> / 
							<a href="https://www.youtube.com/watch?v=_zN-wVwPH1s">video</a> /
							<a href="https://github.com/yenchenlin/nerf-supervision-public">code</a> / 
							<a href="https://colab.research.google.com/drive/13ISri5KD2XeEtsFs25hmZtKhxoDywB5y?usp=sharing">colab</a>				
              <p></p>
              <p>NeRF works better than RGB-D cameras or multi-view stereo when learning object descriptors.</p>
            </td>
          </tr> 

			    <tr onmouseout="refnerf_stop()" onmouseover="refnerf_start()"  bgcolor="#ffffd0">
			      <td style="padding:20px;width:25%;vertical-align:middle">
			        <div class="one">
			          <div class="two" id='refnerf_image'><video  width=100% height=100% muted autoplay loop>
			          <source src="images/refnerf.mp4" type="video/mp4">
			          Your browser does not support the video tag.
			          </video></div>
			          <img src='images/refnerf.jpg' width="160">
			        </div>
			        <script type="text/javascript">
			          function refnerf_start() {
			            document.getElementById('refnerf_image').style.opacity = "1";
			          }

			          function refnerf_stop() {
			            document.getElementById('refnerf_image').style.opacity = "0";
			          }
			          refnerf_stop()
			        </script>
			      </td>
			            <td style="padding:20px;width:75%;vertical-align:middle">
			          <a href="https://dorverbin.github.io/refnerf/index.html">
			            <papertitle>Ref-NeRF: Structured View-Dependent Appearance for Neural Radiance Fields</papertitle>
			          </a>
			          <br>
			          <a href="https://scholar.harvard.edu/dorverbin/home">Dor Verbin</a>,
			          <a href="https://phogzone.com/">Peter Hedman</a>,
			          <a href="https://bmild.github.io/">Ben Mildenhall</a>, <br>
			          <a href="Todd Zickler">Todd Zickler</a>,
			          <strong>Jonathan T. Barron</strong>,
			          <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>
			          <br>
			    <em>CVPR</em>, 2022 &nbsp <font color="red"><strong>(Oral Presentation, Best Student Paper Honorable Mention)</strong></font>
			          <br>
			          <a href="https://dorverbin.github.io/refnerf/index.html">project page</a>
			    /
			          <a href="https://arxiv.org/abs/2112.03907">arXiv</a>
			    /
			          <a href="https://youtu.be/qrdRH9irAlk">video</a>
			          <p></p>
			          <p>Explicitly modeling reflections in NeRF produces realistic shiny surfaces and accurate surface normals, and lets you edit materials.</p>
			        </td>
			      </tr>
						
          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/mip360_sat.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/mip360_sat.jpg' width="160">
              </div>
              <script type="text/javascript">
                function mip360_start() {
                  document.getElementById('mip360_image').style.opacity = "1";
                }

                function mip360_stop() {
                  document.getElementById('mip360_image').style.opacity = "0";
                }
                mip360_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://jonbarron.info/mipnerf360">
                <papertitle>Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>,
              <a href="https://bmild.github.io/">Ben Mildenhall</a>,
              <a href="https://scholar.harvard.edu/dorverbin/home">Dor Verbin</a>,
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <a href="https://phogzone.com/">Peter Hedman</a>
              <br>
							<em>CVPR</em>, 2022 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="http://jonbarron.info/mipnerf360">project page</a>
              /
              <a href="https://arxiv.org/abs/2111.12077">arXiv</a>
              /
              <a href="https://youtu.be/zBSH-k9GbV4">video</a>
              <p></p>
              <p>mip-NeRF can be extended to produce realistic results on unbounded scenes.</p>
            </td>
          </tr> 

          <tr onmouseout="rawnerf_stop()" onmouseover="rawnerf_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='rawnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/rawnerf.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/rawnerf.jpg' width="160">
              </div>
              <script type="text/javascript">
                function rawnerf_start() {
                  document.getElementById('rawnerf_image').style.opacity = "1";
                }

                function rawnerf_stop() {
                  document.getElementById('rawnerf_image').style.opacity = "0";
                }
                rawnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://bmild.github.io/rawnerf/index.html">
                <papertitle>NeRF in the Dark: High Dynamic Range View Synthesis from Noisy Raw Images</papertitle>
              </a>
              <br>
              <a href="https://bmild.github.io/">Ben Mildenhall</a>,
              <a href="https://phogzone.com/">Peter Hedman</a>,
              <a href="http://www.ricardomartinbrualla.com/">Ricardo Martin-Brualla</a>, <br>
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <strong>Jonathan T. Barron</strong>
              <br>
							<em>CVPR</em>, 2022 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://bmild.github.io/rawnerf/index.html">project page</a>
        /
              <a href="https://arxiv.org/abs/2111.13679">arXiv</a>
        /
              <a href="https://www.youtube.com/watch?v=JtBS4KBcKVc">video</a>
              <p></p>
              <p>
								Properly training NeRF on raw camera data enables HDR view synthesis and bokeh, and outperforms multi-image denoising.</p>
            </td>
          </tr> 
					
   
          <tr onmouseout="regnerf_stop()" onmouseover="regnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='regnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/regnerf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/regnerf_before.jpeg' width="160">
              </div>
              <script type="text/javascript">
                function regnerf_start() {
                  document.getElementById('regnerf_image').style.opacity = "1";
                }

                function regnerf_stop() {
                  document.getElementById('regnerf_image').style.opacity = "0";
                }
                regnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://m-niemeyer.github.io/regnerf/index.html">
                <papertitle>RegNeRF: Regularizing Neural Radiance Fields for View Synthesis from Sparse Inputs</papertitle>
              </a>
              <br>
              <a href="https://m-niemeyer.github.io/">Michael Niemeyer</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="https://bmild.github.io/">Ben Mildenhall</a>, <br>
              <a href="https://msmsajjadi.github.io/">Mehdi S. M. Sajjadi</a>, 
              <a href="http://www.cvlibs.net/">Andreas Geiger</a>,
              <a href="http://www2.informatik.uni-freiburg.de/~radwann/">Noha Radwan</a>
              <br>
        <em>CVPR</em>, 2022 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://m-niemeyer.github.io/regnerf/index.html">project page</a>
        /
              <a href="https://arxiv.org/abs/2112.00724">arXiv</a>
        /
              <a href="https://www.youtube.com/watch?v=QyyyvA4-Kwc">video</a>
              <p></p>
              <p>Regularizing unseen views during optimization enables view synthesis from as few as 3 input images.</p>
            </td>
          </tr> 


          <tr onmouseout="blocknerf_stop()" onmouseover="blocknerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='blocknerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/blocknerf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/blocknerf_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function blocknerf_start() {
                  document.getElementById('blocknerf_image').style.opacity = "1";
                }

                function blocknerf_stop() {
                  document.getElementById('blocknerf_image').style.opacity = "0";
                }
                blocknerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://waymo.com/research/block-nerf/">
                <papertitle>Block-NeRF: Scalable Large Scene Neural View Synthesis</papertitle>
              </a>
              <br>
              <a href="http://matthewtancik.com/">Matthew Tancik</a>,
              <a href="http://casser.io/">Vincent Casser</a>,
              <a href="https://sites.google.com/site/skywalkeryxc/">Xinchen Yan</a>,
              <a href="https://scholar.google.com/citations?user=5mJUkI4AAAAJ&hl=en">Sabeek Pradhan</a>, <br>
              <a href="https://bmild.github.io/">Ben Mildenhall</a>,
							<a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="https://www.henrikkretzschmar.com/">Henrik Kretzschmar</a>
              <br>
        <em>CVPR</em>, 2022 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://waymo.com/research/block-nerf/">project page</a>
        /
              <a href="https://arxiv.org/abs/2202.05263">arXiv</a>
        /
              <a href="https://www.youtube.com/watch?v=6lGMCAzBzOQ">video</a>
              <p></p>
              <p>We can do city-scale reconstruction by training multiple NeRFs with millions of images.</p>
            </td>
          </tr>
					
          <tr onmouseout="hnerf_stop()" onmouseover="hnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='hnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/hnerf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/hnerf_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function hnerf_start() {
                  document.getElementById('hnerf_image').style.opacity = "1";
                }

                function hnerf_stop() {
                  document.getElementById('hnerf_image').style.opacity = "0";
                }
                hnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://grail.cs.washington.edu/projects/humannerf/">
                <papertitle>HumanNeRF: Free-viewpoint Rendering of Moving People from Monocular Video</papertitle>
              </a>
              <br>
              <a href="https://homes.cs.washington.edu/~chungyi/">Chung-Yi Weng</a>,
              <a href="https://homes.cs.washington.edu/~curless/">Brian Curless</a>,
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>, <br>
              <strong>Jonathan T. Barron</strong>,
              <a href="https://www.irakemelmacher.com/">Ira Kemelmacher-Shlizerman </a>
              <br>
              <em>CVPR</em>, 2022 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://grail.cs.washington.edu/projects/humannerf/">project page</a>
              /
              <a href="https://arxiv.org/abs/2201.04127">arXiv</a>
              /
              <a href="https://youtu.be/GM-RoZEymmw">video</a>
              <p></p>
              <p>Combining NeRF with pose estimation lets you use a monocular video to do free-viewpoint rendering of a human.</p>
            </td>
          </tr>
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">           
                <a href="https://hsjang.com/">&#10025;</a>
                <a href="http://alexanderli.com/">&#10025;</a>		      
		<a href="https://gabeur.github.io/">&#10025;</a>
		<a href="https://asaran.github.io/">&#10025;</a>
		<a href="https://stevejayh.github.io/">&#10025;</a>
	      	<a href="https://atfortes.github.io/">&#10025;</a>
	        <a href="https://alexj94.github.io/">&#10025;</a>
		<a href="https://jiaxiaosong1002.github.io/">&#10025;</a>
		<a href="https://imethanlee.github.io/">&#10025;</a>
		<a href="https://mirmix.github.io/">&#10025;</a>
		<a href="http://jiayisu.com/">&#10025;</a>
    <a href="https://ahupujr.github.io/">&#10025;</a>
                <br>
                Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
